{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "strategic_classifcation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6mPPnJAtek/rAbeKFE5uI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/causal-dyna-fair/blob/master/strategic_classifcation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGe4qTEmFHo1",
        "outputId": "88161d83-2dfc-4603-fc5d-f27f0422f69e"
      },
      "source": [
        "!git clone https://github.com/ecreager/causal-dyna-fair.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'causal-dyna-fair'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 85 (delta 27), reused 42 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFIYO6xAFLV2",
        "outputId": "3fbe608e-5404-4661-bfbf-bdfbcdd9ca1b"
      },
      "source": [
        "%cd causal-dyna-fair\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "from typing import Dict\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "import gin\n",
        "import torch\n",
        "import structural_eqns as se\n",
        "from utils.policy import get_policy\n",
        "from utils.data import get_data_args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'causal-dyna-fair'\n",
            "/content/causal-dyna-fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwvEc4XFgKN"
      },
      "source": [
        "class OneStepSimulation:\n",
        "    \"\"\"Runs simulation for one step of dynamics under Liu et al 2018 SCM.\"\"\"\n",
        "    def __init__(self,\n",
        "                 f_A: se.StructuralEqn,  # stochastic SE for group membership\n",
        "                 f_X: se.StructuralEqn,  # stochastic SE for indiv scores\n",
        "                 f_Y: se.StructuralEqn,  # stochastic SE for potential repayment\n",
        "                 f_T: se.StructuralEqn,  # SE for threshold loan policy\n",
        "                 f_Xtilde: se.StructuralEqn,  # SE for indiv score change\n",
        "                 f_u: se.StructuralEqn,  # SE for individual utility\n",
        "                 f_Umathcal: se.StructuralEqn,  # SE for avg instit. utility\n",
        "                 f_Deltaj: se.StructuralEqn,  # SE per-group avg score change\n",
        "                 ) -> None:\n",
        "        self.f_A = f_A\n",
        "        self.f_X = f_X\n",
        "        self.f_Y = f_Y\n",
        "        self.f_T = f_T\n",
        "        self.f_Xtilde = f_Xtilde\n",
        "        self.f_u = f_u\n",
        "        self.f_Deltaj = f_Deltaj\n",
        "        self.f_Umathcal = f_Umathcal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdQ53pmaFybZ"
      },
      "source": [
        "   def run(self, num_steps: int, num_samps: int) -> Dict:\n",
        "        \"\"\"Run simulation forward for num_steps and return all observables.\"\"\"\n",
        "        if num_steps != 1:\n",
        "            raise ValueError('Only one-step dynamics are currently supported.')\n",
        "        blank_tensor = torch.zeros(num_samps)\n",
        "        A = self.f_A(blank_tensor)\n",
        "        X = self.f_X(A)\n",
        "        Y = self.f_Y(X, A)\n",
        "        T = self.f_T(X, A)\n",
        "        Xtilde = self.f_Xtilde(X, Y, T)\n",
        "        u = self.f_u(Y, T)\n",
        "        Deltaj = self.f_Deltaj(X, Xtilde, A)\n",
        "        Umathcal = self.f_Umathcal(u)\n",
        "        return_dict = dict(\n",
        "            A=A,\n",
        "            X=X,\n",
        "            Y=Y,\n",
        "            T=T,\n",
        "            u=u,\n",
        "            Xtilde=Xtilde,\n",
        "            Deltaj=Deltaj,\n",
        "            Umathcal=Umathcal,\n",
        "            )\n",
        "        return return_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjwAUMhQF1iW"
      },
      "source": [
        "    def intervene(self, **kwargs):\n",
        "        \"\"\"Update attributes via intervention.\"\"\"\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mceDgq1gF5rP"
      },
      "source": [
        "def main(unused_argv):\n",
        "    \"\"\"Produces figures from Liu et al 2018 and save results.\"\"\"\n",
        "    del unused_argv\n",
        "    gin.parse_config_files_and_bindings([FLAGS.gin_file], FLAGS.gin_param)\n",
        "\n",
        "    seed = gin.query_parameter('%seed')\n",
        "    results_dir = gin.query_parameter('%results_dir')\n",
        "    results_dir = os.path.normpath(results_dir)\n",
        "    num_steps = gin.query_parameter('%num_steps')\n",
        "    num_samps = gin.query_parameter('%num_samps')\n",
        "    utility_repay = gin.query_parameter('%utility_repay')\n",
        "    utility_default = gin.query_parameter('%utility_default')\n",
        "    score_change_repay = gin.query_parameter('%score_change_repay')\n",
        "    score_change_default = gin.query_parameter('%score_change_default')\n",
        "    \n",
        "    torch.manual_seed(seed)\n",
        "    inv_cdfs, loan_repaid_probs, pis, group_size_ratio, scores_list, _ = \\\n",
        "            get_data_args()\n",
        "    import pdb\n",
        "    pdb.set_trace()\n",
        "\n",
        "    utils = (utility_default, utility_repay)\n",
        "    impact = (score_change_default, score_change_repay)\n",
        "    prob_A_equals_1 = group_size_ratio[-1]\n",
        "    f_A = se.IndivGroupMembership(prob_A_equals_1)\n",
        "    f_X = se.InvidScore(*inv_cdfs)\n",
        "    f_Y = se.RepayPotentialLoan(*loan_repaid_probs)\n",
        "    f_T = get_policy(loan_repaid_probs, pis, group_size_ratio, utils, impact,\n",
        "                     scores_list)\n",
        "    f_Xtilde = se.ScoreUpdate(*impact)\n",
        "    f_u = se.InstitUtil(*utils)\n",
        "    f_Umathcal = se.AvgInstitUtil()\n",
        "    f_Deltaj = se.AvgGroupScoreChange() \n",
        "\n",
        "    simulation = OneStepSimulation(\n",
        "f_A, f_X, f_Y, f_T, f_Xtilde, f_u, f_Umathcal, f_Deltaj,\n",
        "        )\n",
        "    results = simulation.run(num_steps, num_samps)\n",
        "    policy_name = gin.query_parameter('%policy_name')\n",
        "    situation = 'situation1' if (utility_default == -4) else 'situation2'\n",
        "    these_thresholds = {\n",
        "        situation:\n",
        "        {policy_name: [f_T.threshold_group_0, f_T.threshold_group_1]}\n",
        "    }\n",
        "    results['threshes'] = these_thresholds\n",
        "\n",
        "   # Finally, write results to disk\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "\n",
        "    # for reproducibility, copy command and script contents to results\n",
        "    if results_dir not in ('.', ):\n",
        "        cmd = 'python ' + ' '.join(sys.argv)\n",
        "        with open(os.path.join(results_dir, 'command.sh'), 'w') as f:\n",
        "            f.write(cmd)\n",
        "        file_basename = os.path.basename(__file__)\n",
        "        this_script = open(__file__, 'r').readlines()\n",
        "        with open(os.path.join(results_dir, file_basename), 'w') as f:\n",
        "            f.write(''.join(this_script))\n",
        "\n",
        "    results_filename = os.path.join(results_dir, 'results.p')\n",
        "    with open(results_filename, 'wb') as f:\n",
        "        _ = pickle.dump(results, f)\n",
        "\n",
        "    # Finally, write gin config to disk\n",
        "    with open(os.path.join(results_dir, 'config.gin'), 'w') as f:\n",
        "        f.write(gin.operative_config_str())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    FLAGS = flags.FLAGS\n",
        "    flags.DEFINE_string(\n",
        "        'gin_file', './config/simulation.gin', 'Path of config file.')\n",
        "    flags.DEFINE_multi_string(\n",
        "        'gin_param', None, 'Newline separated list of Gin parameter bindings.')\n",
        "\n",
        "    app.run(main)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEY7dVRPGc1N",
        "outputId": "d3d88ae9-d4b4-490e-e2bb-4294afcac7a8"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.9.0\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
            "Collecting appnope==0.1.0\n",
            "  Downloading appnope-0.1.0-py2.py3-none-any.whl (4.0 kB)\n",
            "Collecting arrow==0.15.7\n",
            "  Downloading arrow-0.15.7-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting attrs==19.3.0\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: autograd==1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.3)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
            "Collecting binaryornot==0.4.4\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting bleach==3.3.0\n",
            "  Downloading bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting certifi==2020.6.20\n",
            "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: cloudpickle==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.3.0)\n",
            "Collecting cookiecutter==1.7.2\n",
            "  Downloading cookiecutter-1.7.2-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.10.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (4.4.2)\n",
            "Collecting defusedxml==0.6.0\n",
            "  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.3)\n",
            "Collecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting gin-config==0.3.0\n",
            "  Downloading gin_config-0.3.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting gym==0.17.2\n",
            "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (2.10)\n",
            "Collecting importlib-metadata==1.7.0\n",
            "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting ipykernel==5.3.0\n",
            "  Downloading ipykernel-5.3.0-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting ipython==7.16.1\n",
            "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 80.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
            "Collecting ipywidgets==7.5.1\n",
            "  Downloading ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting jedi==0.17.1\n",
            "  Downloading jedi-0.17.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2==2.11.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.11.3)\n",
            "Collecting jinja2-time==0.2.0\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Collecting joblib==0.16.0\n",
            "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
            "\u001b[K     |████████████████████████████████| 300 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting jsonschema==3.2.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (1.0.0)\n",
            "Collecting jupyter-client==6.1.5\n",
            "  Downloading jupyter_client-6.1.5-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting jupyter-console==6.1.0\n",
            "  Downloading jupyter_console-6.1.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jupyter-core==4.6.3\n",
            "  Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.2.0\n",
            "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (3.2.2)\n",
            "Collecting Mesa==0.8.7\n",
            "  Downloading Mesa-0.8.7-py3-none-any.whl (648 kB)\n",
            "\u001b[K     |████████████████████████████████| 648 kB 79.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (0.8.4)\n",
            "Requirement already satisfied: nbconvert==5.6.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.6.1)\n",
            "Collecting nbformat==5.0.7\n",
            "  Downloading nbformat-5.0.7-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 78.8 MB/s \n",
            "\u001b[?25hCollecting networkx==2.4\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.1 MB/s \n",
            "\u001b[?25hCollecting nose==1.3.7\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 30.8 MB/s \n",
            "\u001b[?25hCollecting notebook==6.4.1\n",
            "  Downloading notebook-6.4.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 22.2 MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.5\n",
            "  Downloading numpy-1.16.5-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 120 kB/s \n",
            "\u001b[?25hCollecting packaging==20.4\n",
            "  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pandas==0.24.2\n",
            "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 32.3 MB/s \n",
            "\u001b[?25hCollecting pandocfilters==1.4.2\n",
            "  Downloading pandocfilters-1.4.2.tar.gz (14 kB)\n",
            "Collecting parso==0.7.0\n",
            "  Downloading parso-0.7.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 440 kB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 52)) (0.5.1)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 53)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 54)) (0.7.5)\n",
            "Collecting ply==3.11\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting poyo==0.5.0\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting prometheus-client==0.8.0\n",
            "  Downloading prometheus_client-0.8.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.5\n",
            "  Downloading prompt_toolkit-3.0.5-py3-none-any.whl (351 kB)\n",
            "\u001b[K     |████████████████████████████████| 351 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting ptyprocess==0.6.0\n",
            "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting py-mini-racer==0.4.0\n",
            "  Downloading py_mini_racer-0.4.0-py2.py3-none-manylinux1_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyglet==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 61)) (1.5.0)\n",
            "Collecting Pygments==2.7.4\n",
            "  Downloading Pygments-2.7.4-py3-none-any.whl (950 kB)\n",
            "\u001b[K     |████████████████████████████████| 950 kB 63.4 MB/s \n",
            "\u001b[?25hCollecting Pyomo==5.7\n",
            "  Downloading Pyomo-5.7-cp37-cp37m-manylinux1_x86_64.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 64)) (2.4.7)\n",
            "Collecting pyrsistent==0.16.0\n",
            "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 76.7 MB/s \n",
            "\u001b[?25hCollecting python-slugify==4.0.1\n",
            "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
            "Collecting pytz==2020.1\n",
            "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 73.4 MB/s \n",
            "\u001b[?25hCollecting PyUtilib==6.0.0\n",
            "  Downloading PyUtilib-6.0.0-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting pyzmq==19.0.1\n",
            "  Downloading pyzmq-19.0.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.1 MB/s \n",
            "\u001b[?25hCollecting qtconsole==4.7.5\n",
            "  Downloading qtconsole-4.7.5-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 64.6 MB/s \n",
            "\u001b[?25hCollecting QtPy==1.9.0\n",
            "  Downloading QtPy-1.9.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 475 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 26.8 MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "  Downloading scipy-1.3.0-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.10.1\n",
            "  Downloading seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting Send2Trash==1.5.0\n",
            "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 78)) (1.15.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 79)) (0.0)\n",
            "Collecting statsmodels==0.11.1\n",
            "  Downloading statsmodels-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 18.9 MB/s \n",
            "\u001b[?25hCollecting terminado==0.8.3\n",
            "  Downloading terminado-0.8.3-py2.py3-none-any.whl (33 kB)\n",
            "Collecting testpath==0.4.4\n",
            "  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 83)) (1.3)\n",
            "Collecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting torch==1.5.1\n",
            "  Downloading torch-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (753.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2 MB 14 kB/s \n",
            "\u001b[?25hCollecting tornado==6.0.4\n",
            "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 17.5 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.47.0\n",
            "  Downloading tqdm-4.47.0-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting traitlets==4.3.3\n",
            "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting urllib3==1.26.5\n",
            "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 90)) (0.2.5)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 91)) (0.5.1)\n",
            "Collecting whynot==0.12.0\n",
            "  Downloading whynot-0.12.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: widgetsnbextension==3.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 93)) (3.5.1)\n",
            "Collecting zipp==3.1.0\n",
            "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.1->-r requirements.txt (line 25)) (57.4.0)\n",
            "INFO: pip is looking at multiple versions of nose to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of nbformat to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of nbconvert to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting nbconvert==5.6.1\n",
            "  Downloading nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n",
            "\u001b[K     |████████████████████████████████| 455 kB 81.1 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of mistune to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mistune==0.8.4\n",
            "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "INFO: pip is looking at multiple versions of mesa to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib==3.2.2\n",
            "  Downloading matplotlib-3.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 21.4 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of nose to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of nbformat to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of nbconvert to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-console to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jupyter==1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of mistune to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jinja2-time to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting Jinja2==2.11.3\n",
            "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 64.3 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of mesa to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipython-genutils to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipython-genutils==0.2.0\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-console to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jupyter to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting idna==2.10\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 8.0 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jinja2-time to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gym to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gin-config to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of entrypoints to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting entrypoints==0.3\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipython-genutils to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting decorator==4.4.2\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of gym to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gin-config to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of entrypoints to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cookiecutter to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cloudpickle==1.3.0\n",
            "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting click==7.1.2\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.4 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of chardet to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting chardet==3.0.4\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 79.1 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of cookiecutter to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bleach to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of binaryornot to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting backcall==0.2.0\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of autograd to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting autograd==1.3\n",
            "  Downloading autograd-1.3.tar.gz (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of chardet to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of arrow to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of appnope to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of appdirs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting appdirs==1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bleach to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of binaryornot to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 24), -r requirements.txt (line 34), -r requirements.txt (line 40), -r requirements.txt (line 46) and tornado==6.0.4 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested tornado==6.0.4\n",
            "    ipykernel 5.3.0 depends on tornado>=4.2\n",
            "    jupyter-client 6.1.5 depends on tornado>=4.1\n",
            "    mesa 0.8.7 depends on tornado\n",
            "    notebook 6.4.1 depends on tornado>=6.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEEuShQMPobA"
      },
      "source": [
        "!sh ./bin/icml_results.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXLbfU1cUoOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e02cda-089f-4799-b274-79560975bf29"
      },
      "source": [
        "!git clone https://github.com/zykls/whynot.git\n",
        "%cd whynot\n",
        "!pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whynot'...\n",
            "remote: Enumerating objects: 828, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 828 (delta 23), reused 23 (delta 10), pack-reused 769\u001b[K\n",
            "Receiving objects: 100% (828/828), 12.06 MiB | 11.50 MiB/s, done.\n",
            "Resolving deltas: 100% (479/479), done.\n",
            "/content/whynot\n",
            "Processing /content/whynot\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (1.3)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (0.17.3)\n",
            "Collecting mesa\n",
            "  Downloading Mesa-0.8.9-py3-none-any.whl (668 kB)\n",
            "\u001b[K     |████████████████████████████████| 668 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (1.1.5)\n",
            "Collecting pyomo\n",
            "  Downloading Pyomo-6.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 53.6 MB/s \n",
            "\u001b[?25hCollecting py_mini_racer\n",
            "  Downloading py_mini_racer-0.6.0-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (0.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from whynot==0.12.0) (4.62.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->whynot==0.12.0) (0.16.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->whynot==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->whynot==0.12.0) (1.3.0)\n",
            "Collecting cookiecutter\n",
            "  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mesa->whynot==0.12.0) (5.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from mesa->whynot==0.12.0) (7.1.2)\n",
            "Collecting jinja2-time>=0.2.0\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->whynot==0.12.0) (1.15.0)\n",
            "Collecting poyo>=0.5.0\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->whynot==0.12.0) (5.0.2)\n",
            "Collecting binaryornot>=0.4.4\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->whynot==0.12.0) (2.23.0)\n",
            "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->whynot==0.12.0) (2.11.3)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from binaryornot>=0.4.4->cookiecutter->mesa->whynot==0.12.0) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter->mesa->whynot==0.12.0) (2.0.1)\n",
            "Collecting arrow\n",
            "  Downloading arrow-1.2.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 562 kB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=4.0.0->cookiecutter->mesa->whynot==0.12.0) (1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->whynot==0.12.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->whynot==0.12.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->whynot==0.12.0) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from arrow->jinja2-time>=0.2.0->cookiecutter->mesa->whynot==0.12.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from arrow->jinja2-time>=0.2.0->cookiecutter->mesa->whynot==0.12.0) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->whynot==0.12.0) (2018.9)\n",
            "Collecting ply\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->whynot==0.12.0) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->whynot==0.12.0) (1.0.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->whynot==0.12.0) (0.5.1)\n",
            "Building wheels for collected packages: whynot\n",
            "  Building wheel for whynot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whynot: filename=whynot-0.12.0-py3-none-any.whl size=7538889 sha256=bdb82c44b8dfe0c493074f2ee13de313ea4cecaa8e5ebad933c7948724a3e523\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y9pm7n2d/wheels/41/0b/9e/3f931a0d0a1022ab6408f307ebccf0cf6f528772ec2d22d66d\n",
            "Successfully built whynot\n",
            "Installing collected packages: arrow, poyo, jinja2-time, binaryornot, ply, cookiecutter, pyomo, py-mini-racer, mesa, whynot\n",
            "Successfully installed arrow-1.2.0 binaryornot-0.4.4 cookiecutter-1.7.3 jinja2-time-0.2.0 mesa-0.8.9 ply-3.11 poyo-0.5.0 py-mini-racer-0.6.0 pyomo-6.1.2 whynot-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R9NLwViiObr",
        "outputId": "f5ca0ffc-198c-4c41-ab95-9fe7f227b8ba"
      },
      "source": [
        "import whynot.gym as gym\n",
        "\n",
        "env = gym.make('Credit-v0')\n",
        "env.seed(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFUzicjBiTV3"
      },
      "source": [
        "observation = env.reset()\n",
        "for _ in range(100):\n",
        "    action = env.action_space.sample()  # Replace with your treatment policy\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "        observation = env.reset()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en59vPioiXix",
        "outputId": "f818347e-7023-4c2f-c6f3-c99a83546c16"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import whynot as wn\n",
        "import whynot.gym as gym\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "WwuMdg8MJX9j",
        "outputId": "902e602f-fbe7-4a37-e9d8-c3423472c22f"
      },
      "source": [
        "import scripts.utils as utils"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6f5db4b0b001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YH_TIwbIy4K"
      },
      "source": [
        "\"\"\"Utility functions used by all of the simulators.\"\"\"\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import copy\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import whynot as wn\n",
        "\n",
        "\n",
        "def pretty_print(experiment, dataset, results):\n",
        "    \"\"\"Print the results of running the causal suite on data from an experiment.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        experiment: `whynot.dynamics.DynamicsExperiment` or `whynot.framework.GenericExperiment`\n",
        "            Experiment object used to generate the causal dataset\n",
        "        dataset: `whynot.framework.Dataset`\n",
        "            Dataset object passed to the causal suite.\n",
        "        results:    dict\n",
        "            Dictionary of results returned running `whynot.causal_suite` on the dataset\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Name: \", experiment.name)\n",
        "    print(\"Description: \", experiment.description)\n",
        "    for method, estimate in results.items():\n",
        "        print(f\"Method: {method:<25} \\t\\t Estimate: {estimate.ate:2.2e}\")\n",
        "    print(f\"{' ':<30} \\t\\t\\t Ground Truth: {dataset.sate:2.2e}\")\n",
        "\n",
        "\n",
        "def parallelize(func, arg_lst, show_progress=False, max_workers=None):\n",
        "    \"\"\"Parallel execution of function func across a list of arguments.\n",
        "\n",
        "    The function func and all of the arguments must be pickable. Func is\n",
        "    executed on each elements of arg_list as func(*args)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        func:\n",
        "            Function to repeatedly execute, must be pickable.\n",
        "        arg_lst: iterable\n",
        "            Iterator of unnamed arguments. Each element arg is passed as func(*arg).\n",
        "        show_progress: bool\n",
        "            Whether or not to display a progress bar.\n",
        "        max_workers: int\n",
        "            Maximum number of parallel processes to execute simultaneously.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        results: list\n",
        "            List of outcomes of running func(*arg) on each arg in arg_list.\n",
        "            Results are in the same order as the input arg_list.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def display(range_obj):\n",
        "        if show_progress:\n",
        "            range_obj = tqdm(range_obj)\n",
        "        return range_obj\n",
        "\n",
        "    results = []\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = []\n",
        "        for args in arg_lst:\n",
        "            futures.append(executor.submit(func, *args))\n",
        "        for future in display(futures):\n",
        "            data = future.result()\n",
        "            results.append(data)\n",
        "    return results\n",
        "\n",
        "\n",
        "def parallel_run_estimators(causal_datasets):\n",
        "    \"\"\"Run causal suite in parallel for repeated trials of a causal experiment.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        causal_datasets: dict\n",
        "            Dictionary mapping an experiment setting to a list of datasets\n",
        "            representing repeated trials of the experiment.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        all_estimates: dict\n",
        "            Dictionary mapping estimators name and experimental setting\n",
        "            to a list of `wn.InferenceResult` objects for each trial,\n",
        "            e.g. all_estimates['ols'][200][3] is the InferenceResult for ols\n",
        "            on the 3rd trial of the experiment with setting 200.\n",
        "\n",
        "    \"\"\"\n",
        "    all_estimates = defaultdict(lambda: defaultdict(list))\n",
        "    for key, trials in causal_datasets.items():\n",
        "        parallel_args = [\n",
        "            (dataset.covariates, dataset.treatments, dataset.outcomes)\n",
        "            for dataset in trials\n",
        "        ]\n",
        "        all_trial_estimates = parallelize(\n",
        "            wn.causal_suite, parallel_args, show_progress=True\n",
        "        )\n",
        "        for estimates in all_trial_estimates:\n",
        "            for method, estimate in estimates.items():\n",
        "                all_estimates[method][key].append(estimate)\n",
        "    return all_estimates\n",
        "\n",
        "\n",
        "def sample_size_experiment(\n",
        "    experiment, sample_sizes, num_trials, parameters=None, seeds=None, verbose=False\n",
        "):\n",
        "    \"\"\"Repeatedly run an experiment at different sample sizes.\n",
        "\n",
        "    All of the datasets are generate sequentially, and the estimators are run in\n",
        "    parallel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        experiment: `whynot.dynamics.DynamicsExperiment` or `whynot.framework.GenericExperiment`\n",
        "            Instantiated experiment object.\n",
        "        sample_sizes: list\n",
        "            List of sample sizes to run the experiment\n",
        "        num_trials: int\n",
        "            How many trials to run each experiment for a fixed sample size.\n",
        "        parameters: dict\n",
        "            Dictionary of {param_name: param_value} fixing non-varying parameters\n",
        "            for the experiment.\n",
        "        (optional) seeds: list\n",
        "           List of random seeds to use for each trial. If specified, should have\n",
        "           length num_trials.\n",
        "        (optional) verbose: bool\n",
        "            Print status updates.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        estimates: dict\n",
        "            Dictionary mapping each method to a dictionary of sample_size to\n",
        "            `whynot.framework.InferenceResults` for each trial at the given\n",
        "            sample size.\n",
        "\n",
        "                estimates[method_name] = {\n",
        "                    sample_size1: [estimates_for_sample_size_1],\n",
        "                    sample_size2: [estimates_for_sample_size_2],\n",
        "                    ...}\n",
        "\n",
        "        sample_ates: dict\n",
        "            Dictionary mapping sample_size to the sample_ate for each trial.\n",
        "\n",
        "                sample_ates = {\n",
        "                    sample_size1: [sample_ates_for_sample_size_1],\n",
        "                    sample_size2: [sample_ates_for_sample_size_2],\n",
        "                    ...}\n",
        "\n",
        "    \"\"\"\n",
        "    if seeds is None:\n",
        "        seeds = [None] * num_trials\n",
        "    assert len(seeds) == num_trials\n",
        "    if parameters is None:\n",
        "        parameters = {}\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Generating causal datasets...\")\n",
        "    datasets = defaultdict(list)\n",
        "    all_sates = defaultdict(list)\n",
        "    for (sample_size, seed) in itertools.product(sample_sizes, seeds):\n",
        "        dataset = experiment.run(num_samples=sample_size, seed=seed, **parameters)\n",
        "        all_sates[sample_size].append(dataset.sate)\n",
        "        datasets[sample_size].append(dataset)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Running estimators...\")\n",
        "    return parallel_run_estimators(datasets), all_sates\n",
        "\n",
        "\n",
        "def parameter_sweep_experiment(\n",
        "    experiment,\n",
        "    sample_size,\n",
        "    num_trials,\n",
        "    parameter_name,\n",
        "    parameter_values,\n",
        "    fixed_parameters=None,\n",
        "    seeds=None,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Repeatedly run an experiment for different values of a parameter.\n",
        "\n",
        "    All of the datasets are generate sequentially, and the estimators are run in\n",
        "    parallel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        experiment: `whynot.dynamics.DynamicsExperiment` or `whynot.framework.GenericExperiment`\n",
        "            Instantiated experiment object.\n",
        "        sample_size: int\n",
        "            Sample size to use for all experiments.\n",
        "        num_trials: int\n",
        "            How many trials to run each experiment for a fixed parameter setting.\n",
        "        parameter_name: str\n",
        "            Name of the parameter to vary.\n",
        "        parameter_values: list\n",
        "            List of values of the parameter to vary\n",
        "        fixed_parameters: dict\n",
        "            Dictionary of {param_name: param_value} fixing non-varying parameters\n",
        "            for the experiment.\n",
        "        (optional) seeds: list\n",
        "           List of random seeds to use for each trial. If specified, should have\n",
        "           length num_trials.\n",
        "        (optional) verbose: bool\n",
        "            Print status updates.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        estimates: dict\n",
        "            Dictionary mapping each method to a dictionary of parameter_value to\n",
        "            `whynot.framework.InferenceResults` for each trial at the given\n",
        "            sample size.\n",
        "\n",
        "                estimates[method_name] = {\n",
        "                    parameter_value1: [estimates_for_parameter_value1],\n",
        "                    parameter_value2: [estimates_for_parameter_value2],\n",
        "                    ...}\n",
        "\n",
        "        sample_ates: dict\n",
        "            Dictionary mapping parameter_value to the sample_ate for each trial.\n",
        "\n",
        "    \"\"\"\n",
        "    if seeds is None:\n",
        "        seeds = [None] * num_trials\n",
        "    assert len(seeds) == num_trials\n",
        "    if fixed_parameters is None:\n",
        "        fixed_parameters = {}\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Generating causal datasets...\")\n",
        "    datasets = defaultdict(list)\n",
        "    sample_ates = defaultdict(list)\n",
        "    for (parameter_value, seed) in itertools.product(parameter_values, seeds):\n",
        "        parameters = copy.deepcopy(fixed_parameters)\n",
        "        parameters[parameter_name] = parameter_value\n",
        "        dataset = experiment.run(num_samples=sample_size, seed=seed, **parameters)\n",
        "        sample_ates[parameter_value].append(dataset.sate)\n",
        "        datasets[parameter_value].append(dataset)\n",
        "    if verbose:\n",
        "        print(\"Running estimators...\")\n",
        "    return parallel_run_estimators(datasets), sample_ates\n",
        "\n",
        "\n",
        "def summarize_errors(estimates, sample_ates, metric):\n",
        "    \"\"\"Summarize estimator errors for a parameter or sample size sweep.\n",
        "\n",
        "    Currently, this function only supports summaries for ATE estimation.\n",
        "    This function should be used in conjunction with parameter_sweep_experiment\n",
        "    and sample_size_experiment.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        estimates: dict\n",
        "            Dictionary mapping method_names to a dictionary of experiment\n",
        "            settings and `whynot.InferenceResults` as returned by\n",
        "            parameter_sweep_experiment.\n",
        "        sample_ates: dict\n",
        "            Dictionary mapping experiment settings to sample ates.\n",
        "        metric: str\n",
        "            One of 'relative_error' or 'absolute_error' for reporting results.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        summary: dict\n",
        "            Dictionary mapping method name to a tuple of (means, stds), where\n",
        "            means is a list of mean error for each experimental setting, and\n",
        "            similarly for standard deviation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def score(est, sate):\n",
        "        if metric == \"relative_error\":\n",
        "            return np.abs((est - sate) / sate)\n",
        "\n",
        "        if metric == \"absolute_error\":\n",
        "            return np.abs(est - sate)\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    summary = {}\n",
        "    for method, results in estimates.items():\n",
        "        means, stds = [], []\n",
        "        for setting, inferences in results.items():\n",
        "            scores = []\n",
        "            for inference, sample_ate in zip(inferences, sample_ates[setting]):\n",
        "                scores.append(score(inference.ate, sample_ate))\n",
        "            means.append(np.mean(scores))\n",
        "            stds.append(np.std(scores) / np.sqrt(len(scores)))\n",
        "        summary[method] = (means, stds)\n",
        "    return summary\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn0JMgckI4Ud",
        "outputId": "1f8f26ea-34fc-474c-c58d-c49a2e81a88c"
      },
      "source": [
        "base_dataset = env.initial_state.values()\n",
        "base_features, base_labels = base_dataset[\"features\"], base_dataset[\"labels\"]\n",
        "num_agents, num_features = base_features.shape\n",
        "print(f\"The dataset has {num_agents} agents and {num_features} features.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 18357 agents and 11 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "mP5YROSFI-1q",
        "outputId": "5dc44094-999c-4c19-c63c-2b9ee2da2f1e"
      },
      "source": [
        "l2_penalty = 1.0 / num_agents\n",
        "baseline_theta = utils.fit_logistic_regression(base_features, base_labels, l2_penalty)\n",
        "baseline_acc = ((base_features.dot(baseline_theta) > 0)  == base_labels).mean()\n",
        "print(f\"Baseline logistic regresion model accuracy: {100 * baseline_acc:.2f}%\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-15d21cb08d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml2_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbaseline_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_penalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbaseline_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_theta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0mbase_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Baseline logistic regresion model accuracy: {100 * baseline_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fit_logistic_regression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZ7gS-VJfI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}